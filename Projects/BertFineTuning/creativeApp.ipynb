{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58eb7bad-ef1c-4b28-8a6b-c977bfe7609a",
   "metadata": {},
   "source": [
    "#### !pip install datasets\n",
    "\n",
    "!pip install transformers\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35705f58-890e-44cd-b26c-e64764ad822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/anaconda3/lib/python3.12/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (0.33.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2024.12.14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -U accelerate\n",
    "import accelerate\n",
    "\n",
    "accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b81469-5e25-4a35-b71c-bd97cf8acf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e06cc1ea-1151-47ff-9281-ba60d9899d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\", 'date': 'Mon Apr 06 22:19:45 PDT 2009', 'user': '_TheSpecialOne_', 'sentiment': 0, 'query': 'NO_QUERY'}\n",
      "{'text': [\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\", \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\", '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds', 'my whole body feels itchy and like its on fire ', \"@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"], 'date': ['Mon Apr 06 22:19:45 PDT 2009', 'Mon Apr 06 22:19:49 PDT 2009', 'Mon Apr 06 22:19:53 PDT 2009', 'Mon Apr 06 22:19:57 PDT 2009', 'Mon Apr 06 22:19:57 PDT 2009'], 'user': ['_TheSpecialOne_', 'scotthamilton', 'mattycus', 'ElleCTF', 'Karoli'], 'sentiment': [0, 0, 0, 0, 0], 'query': ['NO_QUERY', 'NO_QUERY', 'NO_QUERY', 'NO_QUERY', 'NO_QUERY']}\n",
      "                                                 text  \\\n",
      "0   @JonathanRKnight @silver_tulip27 Um, that woul...   \n",
      "1       I'm doing my homework. It's gosh darn hard!!    \n",
      "2   definitely no vacation for me...   http://plur...   \n",
      "3   'study group extraordinare' about to leave cam...   \n",
      "4   Why can't airfare go down? Or, why do I have t...   \n",
      "5   @j_stricko I found it pretty frustrating. stup...   \n",
      "6         @lenesha but Im not feeling well, mommy...    \n",
      "7        @lovebscott Nope, I'm Right Along Wit' You!    \n",
      "8               so a murder? gotcha.  Cant believe it   \n",
      "9   @nbensalem i'm sitting at my house and i'm soo...   \n",
      "10  Ordered some maternity clothes online, which c...   \n",
      "11                                     @citizensheep    \n",
      "12    @thesage1014 I wish I could! Gotta work though    \n",
      "13  @SeaGhostdesigns what happened to you on Satur...   \n",
      "14                                   @GirlsGoneChild    \n",
      "15                                 Can't fall asleep    \n",
      "16   I have mouth ulcer  so painful to talk and eat!    \n",
      "17  @danphelan Urgh, it was just the video, and th...   \n",
      "18  my dog can't move anymore. praying that he wil...   \n",
      "19  @Kal_Penn you were pretty much my fave...not m...   \n",
      "\n",
      "                            date             user  sentiment     query  \n",
      "0   Mon Apr 06 23:28:50 PDT 2009      Saphyre1969          0  NO_QUERY  \n",
      "1   Mon Apr 06 23:28:58 PDT 2009      nurainiffah          0  NO_QUERY  \n",
      "2   Mon Apr 06 23:29:00 PDT 2009        francheza          0  NO_QUERY  \n",
      "3   Mon Apr 06 23:30:10 PDT 2009       BrandesAsh          0  NO_QUERY  \n",
      "4   Mon Apr 06 23:30:10 PDT 2009    Buffaliscious          0  NO_QUERY  \n",
      "5   Mon Apr 06 23:30:16 PDT 2009         bendoyle          0  NO_QUERY  \n",
      "6   Mon Apr 06 23:30:17 PDT 2009     Melamachinko          0  NO_QUERY  \n",
      "7   Mon Apr 06 23:30:18 PDT 2009        tedarrius          0  NO_QUERY  \n",
      "8   Mon Apr 06 23:30:18 PDT 2009     berlingalvan          0  NO_QUERY  \n",
      "9   Mon Apr 06 23:30:18 PDT 2009        kurosevic          0  NO_QUERY  \n",
      "10  Mon Apr 06 23:30:20 PDT 2009          impathy          0  NO_QUERY  \n",
      "11  Mon Apr 06 23:30:23 PDT 2009       gabysslave          0  NO_QUERY  \n",
      "12  Mon Apr 06 23:30:29 PDT 2009           Broskt          0  NO_QUERY  \n",
      "13  Mon Apr 06 23:30:39 PDT 2009      annabannana          0  NO_QUERY  \n",
      "14  Mon Apr 06 23:30:43 PDT 2009      PunkRockMom          0  NO_QUERY  \n",
      "15  Mon Apr 06 23:30:44 PDT 2009  mizzoutigress09          0  NO_QUERY  \n",
      "16  Mon Apr 06 23:30:46 PDT 2009       Askmewhats          0  NO_QUERY  \n",
      "17  Mon Apr 06 23:30:48 PDT 2009       JustJames_          0  NO_QUERY  \n",
      "18  Mon Apr 06 23:30:49 PDT 2009      Christieeee          0  NO_QUERY  \n",
      "19  Mon Apr 06 23:30:51 PDT 2009            k_eak          0  NO_QUERY  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the Sentiment140 dataset\n",
    "dataset = load_dataset(\"stanfordnlp/sentiment140\")\n",
    "\n",
    "# Print the first few examples from the training set (as raw Python dicts)\n",
    "print(dataset[\"train\"][0])        # Just the first example\n",
    "print(dataset[\"train\"][:5])      # First 5 examples\n",
    "\n",
    "# OR if you want to inspect it as a mini table:\n",
    "import pandas as pd\n",
    "df_raw = pd.DataFrame(dataset[\"train\"][1000:1020])  # Show first 20 rows\n",
    "print(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d11b29b-5f42-4b64-a1ce-4b8c32d5f808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in train split: 1600000\n",
      "Label distribution:\n",
      "Sentiment 0: 800000 samples\n",
      "Sentiment 4: 800000 samples\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"sentiment140\")\n",
    "\n",
    "# Check total number of samples\n",
    "print(f\"Total samples in train split: {len(dataset['train'])}\")\n",
    "\n",
    "# Look at unique sentiment labels and their counts\n",
    "labels = dataset[\"train\"][\"sentiment\"]\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "print(\"Label distribution:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Sentiment {label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5212f6a0-38b5-4f47-bcd2-691f315b6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens: 99\n",
      "Average tokens: 22.445\n",
      "90th percentile: 37.0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset = load_dataset('stanfordnlp/sentiment140')\n",
    "\n",
    "# STEP 1: Analyze tweet length to choose a good max_length\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sample_texts = dataset[\"train\"].select(range(10000))[\"text\"]\n",
    "lengths = [len(tokenizer.encode(text, truncation=False)) for text in sample_texts]\n",
    "\n",
    "print(\"Max tokens:\", max(lengths))\n",
    "print(\"Average tokens:\", np.mean(lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "569ee0a4-3d3b-4e51-8a98-b69b4ae44d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens: 99\n",
      "Average tokens: 22.445\n",
      "90th percentile: 37.0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('stanfordnlp/sentiment140')\n",
    "\n",
    "# STEP 1: Analyze tweet length to choose a good max_length\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sample_texts = dataset[\"train\"].select(range(10000))[\"text\"]\n",
    "lengths = [len(tokenizer.encode(text, truncation=False)) for text in sample_texts]\n",
    "\n",
    "print(\"Max tokens:\", max(lengths))\n",
    "print(\"Average tokens:\", np.mean(lengths))\n",
    "print(\"90th percentile:\", np.percentile(lengths, 90))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdae4463-b7a3-4af4-ad37-b0a8d7f8c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.824\n",
      "F1 Score: 0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions and compute metrics\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c44ee238-3efa-48b6-a8ab-118a4563b862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 05:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.434240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>0.437475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.4374752938747406, 'eval_runtime': 8.3209, 'eval_samples_per_second': 60.09, 'eval_steps_per_second': 3.846, 'epoch': 2.0}\n",
      "Accuracy: 0.824\n",
      "F1 Score: 0.8294573643410853\n"
     ]
    }
   ],
   "source": [
    "#batch 16, epochs 2, \n",
    "# Load the dataset\n",
    "dataset = load_dataset('stanfordnlp/sentiment140')\n",
    "\n",
    "# Map sentiment labels: 0 = negative, 4 = positive → convert 4 to 1\n",
    "def map_labels(example):\n",
    "    example[\"sentiment\"] = 0 if example[\"sentiment\"] == 0 else 1\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(map_labels)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=70)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"sentiment\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Sample a subset for training/testing to speed things up\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "test_dataset = tokenized_datasets[\"train\"].shuffle(seed=123).select(range(500))  \n",
    "\n",
    "# Load the BERT model for sequence classification (binary)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size= 16,\n",
    "    per_device_eval_batch_size= 16,\n",
    "    num_train_epochs= 2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    ")\n",
    "\n",
    "# Define a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_result}\")\n",
    "# Make predictions and compute metrics\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c36066f-f92c-4d32-9dff-2527cd4db061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 05:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>0.469135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.455802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.4558018743991852, 'eval_runtime': 8.7743, 'eval_samples_per_second': 56.985, 'eval_steps_per_second': 3.647, 'epoch': 2.0}\n",
      "Accuracy: 0.802\n",
      "F1 Score: 0.8107074569789675\n"
     ]
    }
   ],
   "source": [
    "#CASED, batch 16, epochs 2, \n",
    "# Load the dataset\n",
    "dataset = load_dataset('stanfordnlp/sentiment140')\n",
    "\n",
    "# Map sentiment labels: 0 = negative, 4 = positive → convert 4 to 1\n",
    "def map_labels(example):\n",
    "    example[\"sentiment\"] = 0 if example[\"sentiment\"] == 0 else 1\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(map_labels)\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=70)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Rename the sentiment column to 'labels' for training compatibility\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"sentiment\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Sample a subset for training/testing to speed things up\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "test_dataset = tokenized_datasets[\"train\"].shuffle(seed=123).select(range(500))  \n",
    "\n",
    "# Load the BERT model for sequence classification (binary)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-large-cased', num_labels=2)\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size= 16,\n",
    "    per_device_eval_batch_size= 16,\n",
    "    num_train_epochs= 2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    ")\n",
    "\n",
    "# Define a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_result}\")\n",
    "# Make predictions and compute metrics\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6388808-b710-4e8a-963b-c22b56b0b96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
